{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondab159dead09f04ba0b61ce20ec22ca146",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(Dataset):\n",
    "    def __init__(self, split, trasform = None):\n",
    "        base_dir='./datasets/'\n",
    "\n",
    "        path =os.path.join(base_dir,'64x64_SIGNS/{}'.format(split))\n",
    "\n",
    "        files = os.listdir(path)\n",
    "\n",
    "        self.filenames = [os.path.join(path,f) for f in files if f.endswith('.jpg')]\n",
    "\n",
    "        self.targets = [int(f[0]) for f in files]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.filenames[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = Loader('train_signs',transform)\n",
    "trainLoader = DataLoader(trainSet, batch_size=2)\n",
    "\n",
    "valSet = Loader('val_signs',transform)\n",
    "valLoader = DataLoader(valSet, batch_size=1)\n",
    "\n",
    "testSet = Loader('test_signs',transform)\n",
    "testLoader = DataLoader(testSet, batch_size=35)\n",
    "\n",
    "dataLoader = {'train':trainLoader,'val':valLoader,'test':testLoader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=9,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=9,out_channels=12,kernel_size=5)\n",
    "        self.fc1 = nn.Linear(2028,1000)\n",
    "        self.fc2 = nn.Linear(1000,500)\n",
    "        self.fc3 = nn.Linear(500,6)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu( self.conv1(x)))\n",
    "        x = self.pool(F.relu( self.conv2(x)))\n",
    "\n",
    "        x = x.view(-1,2028)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        x = F.log_softmax(x,dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (conv1): Conv2d(3, 9, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(9, 12, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=2028, out_features=1000, bias=True)\n  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n  (fc3): Linear(in_features=500, out_features=6, bias=True)\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim \n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "loss:  0.0009694099426269531       epoc:  9\nloss:  0.015195846557617188       epoc:  9\nloss:  0.023121356964111328       epoc:  9\nloss:  0.0001957416534423828       epoc:  9\nloss:  6.341934204101562e-05       epoc:  9\nloss:  0.13543909788131714       epoc:  9\nloss:  0.0004260540008544922       epoc:  9\nloss:  0.19854259490966797       epoc:  9\nloss:  3.24249267578125e-05       epoc:  9\nloss:  0.0004961490631103516       epoc:  9\nloss:  0.0033464431762695312       epoc:  9\nloss:  0.012044310569763184       epoc:  9\nloss:  0.00033593177795410156       epoc:  9\nloss:  0.08618021011352539       epoc:  9\nloss:  9.5367431640625e-07       epoc:  9\nloss:  0.0       epoc:  9\nloss:  3.695487976074219e-05       epoc:  9\nloss:  0.00025653839111328125       epoc:  9\nloss:  0.0010724067687988281       epoc:  9\nloss:  2.5272369384765625e-05       epoc:  9\nloss:  0.025109529495239258       epoc:  9\nloss:  0.0012431144714355469       epoc:  9\nloss:  0.0016155242919921875       epoc:  9\nloss:  0.0015310049057006836       epoc:  9\nloss:  0.013293027877807617       epoc:  9\nloss:  0.058766305446624756       epoc:  9\nloss:  7.224082946777344e-05       epoc:  9\nloss:  7.677078247070312e-05       epoc:  9\nloss:  0.05150103569030762       epoc:  9\nloss:  0.0019304752349853516       epoc:  9\nloss:  0.03049468994140625       epoc:  9\nloss:  0.0012118816375732422       epoc:  9\nloss:  0.00023484230041503906       epoc:  9\nloss:  4.482269287109375e-05       epoc:  9\nloss:  0.012680768966674805       epoc:  9\nloss:  0.03809952735900879       epoc:  9\nloss:  0.12988948822021484       epoc:  9\nloss:  0.0016460418701171875       epoc:  9\nloss:  0.0037698745727539062       epoc:  9\nloss:  0.0005011558532714844       epoc:  9\nloss:  0.2537994384765625       epoc:  9\nloss:  0.010256528854370117       epoc:  9\nloss:  0.006286025047302246       epoc:  9\nloss:  5.1975250244140625e-05       epoc:  9\nloss:  1.33514404296875e-05       epoc:  9\nloss:  0.011137962341308594       epoc:  9\nloss:  0.004757404327392578       epoc:  9\nloss:  0.0726933479309082       epoc:  9\nloss:  0.0018489360809326172       epoc:  9\nloss:  0.0       epoc:  9\nloss:  0.0001678466796875       epoc:  9\nloss:  0.0       epoc:  9\nloss:  0.0019032955169677734       epoc:  9\nloss:  0.00501704216003418       epoc:  9\nloss:  4.76837158203125e-07       epoc:  9\nloss:  3.409385681152344e-05       epoc:  9\nloss:  0.01696956157684326       epoc:  9\nloss:  0.00038743019104003906       epoc:  9\nloss:  0.0035026073455810547       epoc:  9\nloss:  1.9073486328125e-06       epoc:  9\nloss:  0.0014678239822387695       epoc:  9\nloss:  0.0009593963623046875       epoc:  9\nloss:  0.008348703384399414       epoc:  9\nloss:  0.013175010681152344       epoc:  9\nloss:  0.4891502559185028       epoc:  9\nloss:  0.024220705032348633       epoc:  9\nloss:  6.198883056640625e-06       epoc:  9\nloss:  0.0018374919891357422       epoc:  9\nloss:  0.0003688335418701172       epoc:  9\nloss:  0.006886959075927734       epoc:  9\nloss:  2.68678617477417       epoc:  9\nloss:  0.003674626350402832       epoc:  9\nloss:  0.0027337074279785156       epoc:  9\nloss:  0.09070205688476562       epoc:  9\nloss:  3.0634734630584717       epoc:  9\nloss:  0.013549327850341797       epoc:  9\nloss:  0.0008082389831542969       epoc:  9\nloss:  3.814697265625e-05       epoc:  9\nloss:  1.3893065452575684       epoc:  9\nloss:  4.291534423828125e-06       epoc:  9\nloss:  0.0012352466583251953       epoc:  9\nloss:  0.002048015594482422       epoc:  9\nloss:  1.5584933757781982       epoc:  9\nloss:  0.003958702087402344       epoc:  9\nloss:  0.9737478494644165       epoc:  9\nloss:  0.0004353523254394531       epoc:  9\nloss:  0.0005819797515869141       epoc:  9\nloss:  0.005214691162109375       epoc:  9\nloss:  0.008862018585205078       epoc:  9\nloss:  0.017289400100708008       epoc:  9\nloss:  0.026313185691833496       epoc:  9\nloss:  0.09650921821594238       epoc:  9\nloss:  0.04917335510253906       epoc:  9\nloss:  0.03881990909576416       epoc:  9\nloss:  0.034171223640441895       epoc:  9\nloss:  0.031018853187561035       epoc:  9\nloss:  0.0008389949798583984       epoc:  9\nloss:  0.009607315063476562       epoc:  9\nloss:  0.0029630661010742188       epoc:  9\nloss:  8.678436279296875e-05       epoc:  9\nloss:  0.08119213581085205       epoc:  9\nloss:  0.0027818679809570312       epoc:  9\nloss:  0.07917654514312744       epoc:  9\nloss:  0.0025904178619384766       epoc:  9\nloss:  0.4783073663711548       epoc:  9\nloss:  0.0022127628326416016       epoc:  9\nloss:  0.0002052783966064453       epoc:  9\nloss:  0.08501708507537842       epoc:  9\nloss:  2.384185791015625e-06       epoc:  9\nloss:  0.45108771324157715       epoc:  9\nloss:  0.0002009868621826172       epoc:  9\nloss:  0.6418020725250244       epoc:  9\nloss:  0.017642736434936523       epoc:  9\nloss:  0.10420000553131104       epoc:  9\nloss:  3.337860107421875e-06       epoc:  9\nloss:  0.0037386417388916016       epoc:  9\nloss:  0.0012807846069335938       epoc:  9\nloss:  0.11854922771453857       epoc:  9\nloss:  0.03250682353973389       epoc:  9\nloss:  0.2934384047985077       epoc:  9\nloss:  0.0012328624725341797       epoc:  9\nloss:  0.009384870529174805       epoc:  9\nloss:  0.024661898612976074       epoc:  9\nloss:  0.4886370897293091       epoc:  9\nloss:  0.019144177436828613       epoc:  9\nloss:  0.02088487148284912       epoc:  9\nloss:  0.06887030601501465       epoc:  9\nloss:  1.3440834283828735       epoc:  9\nloss:  2.5264182090759277       epoc:  9\nloss:  0.0048944950103759766       epoc:  9\nloss:  0.29964494705200195       epoc:  9\nloss:  0.014412403106689453       epoc:  9\nloss:  0.016676783561706543       epoc:  9\nloss:  0.0645376443862915       epoc:  9\nloss:  0.0001742839813232422       epoc:  9\nloss:  2.6385810375213623       epoc:  9\nloss:  0.027249932289123535       epoc:  9\nloss:  0.000118255615234375       epoc:  9\nloss:  0.0006792545318603516       epoc:  9\nloss:  0.8508976697921753       epoc:  9\nloss:  0.001588582992553711       epoc:  9\nloss:  0.018923640251159668       epoc:  9\nloss:  1.8596649169921875e-05       epoc:  9\nloss:  0.004288673400878906       epoc:  9\nloss:  0.7423259019851685       epoc:  9\nloss:  0.004860639572143555       epoc:  9\nloss:  0.0005152225494384766       epoc:  9\nloss:  0.000989675521850586       epoc:  9\nloss:  0.17317509651184082       epoc:  9\nloss:  0.007161855697631836       epoc:  9\nloss:  0.0005609989166259766       epoc:  9\nloss:  0.042179107666015625       epoc:  9\nloss:  0.3532518446445465       epoc:  9\nloss:  0.0015981197357177734       epoc:  9\nloss:  0.0005128383636474609       epoc:  9\nloss:  0.014680147171020508       epoc:  9\nloss:  0.008547067642211914       epoc:  9\nloss:  0.8011860251426697       epoc:  9\nloss:  0.23036181926727295       epoc:  9\nloss:  0.0       epoc:  9\nloss:  0.05197620391845703       epoc:  9\nloss:  0.011197566986083984       epoc:  9\nloss:  0.2016838788986206       epoc:  9\nloss:  0.23869562149047852       epoc:  9\nloss:  7.3909759521484375e-06       epoc:  9\nloss:  0.9628990888595581       epoc:  9\nloss:  0.007699251174926758       epoc:  9\nloss:  0.45915257930755615       epoc:  9\nloss:  0.023535490036010742       epoc:  9\nloss:  0.16536855697631836       epoc:  9\nloss:  0.0       epoc:  9\nloss:  0.002300262451171875       epoc:  9\nloss:  0.00036525726318359375       epoc:  9\nloss:  0.03264951705932617       epoc:  9\nloss:  2.193450927734375e-05       epoc:  9\nloss:  0.01839768886566162       epoc:  9\nloss:  0.0023682117462158203       epoc:  9\nloss:  0.007357478141784668       epoc:  9\nloss:  2.0655791759490967       epoc:  9\nloss:  0.00013518333435058594       epoc:  9\nloss:  0.0002884864807128906       epoc:  9\nloss:  0.0022492408752441406       epoc:  9\nloss:  0.0035200119018554688       epoc:  9\nloss:  0.5373824834823608       epoc:  9\nloss:  0.00629878044128418       epoc:  9\nloss:  2.6678943634033203       epoc:  9\nloss:  0.0009062290191650391       epoc:  9\nloss:  0.028544187545776367       epoc:  9\nloss:  0.7927401065826416       epoc:  9\nloss:  0.0010805130004882812       epoc:  9\nloss:  0.044127702713012695       epoc:  9\nloss:  1.043108582496643       epoc:  9\nloss:  0.13524174690246582       epoc:  9\nloss:  0.07638341188430786       epoc:  9\nloss:  0.006539821624755859       epoc:  9\nloss:  0.006937742233276367       epoc:  9\nloss:  0.23767691850662231       epoc:  9\nloss:  0.0       epoc:  9\nloss:  0.0012874603271484375       epoc:  9\nloss:  0.1444091796875       epoc:  9\nloss:  0.09957671165466309       epoc:  9\nloss:  0.04651522636413574       epoc:  9\nloss:  0.011050701141357422       epoc:  9\nloss:  0.07681488990783691       epoc:  9\nloss:  0.12483000755310059       epoc:  9\nloss:  0.008530378341674805       epoc:  9\nloss:  0.0047724246978759766       epoc:  9\nloss:  0.2114276885986328       epoc:  9\nloss:  3.8623809814453125e-05       epoc:  9\nloss:  0.008564949035644531       epoc:  9\nloss:  0.0003478527069091797       epoc:  9\nloss:  2.275865316390991       epoc:  9\nloss:  0.0001499652862548828       epoc:  9\nloss:  0.4286537170410156       epoc:  9\nloss:  0.12974822521209717       epoc:  9\nloss:  0.013594627380371094       epoc:  9\nloss:  0.07743537425994873       epoc:  9\nloss:  0.00047087669372558594       epoc:  9\nloss:  0.007924199104309082       epoc:  9\nloss:  0.07595515251159668       epoc:  9\nloss:  1.0966331958770752       epoc:  9\nloss:  1.4591033458709717       epoc:  9\nloss:  0.008031129837036133       epoc:  9\nloss:  0.0038721561431884766       epoc:  9\nloss:  0.0002715587615966797       epoc:  9\nloss:  0.9433833360671997       epoc:  9\nloss:  0.005572319030761719       epoc:  9\nloss:  0.00011754035949707031       epoc:  9\nloss:  0.008428335189819336       epoc:  9\nloss:  0.7633227109909058       epoc:  9\nloss:  0.0       epoc:  9\nloss:  0.07064676284790039       epoc:  9\nloss:  0.0003857612609863281       epoc:  9\nloss:  0.005531787872314453       epoc:  9\nloss:  0.3725878596305847       epoc:  9\nloss:  0.022225022315979004       epoc:  9\nloss:  0.0007200241088867188       epoc:  9\nloss:  0.47505983710289       epoc:  9\nloss:  0.04870891571044922       epoc:  9\nloss:  0.025725126266479492       epoc:  9\nloss:  0.018358469009399414       epoc:  9\nloss:  0.009146451950073242       epoc:  9\nloss:  0.00023818016052246094       epoc:  9\nloss:  0.013871908187866211       epoc:  9\nloss:  0.023608684539794922       epoc:  9\nloss:  0.03152811527252197       epoc:  9\nloss:  0.0034341812133789062       epoc:  9\nloss:  0.0016252994537353516       epoc:  9\nloss:  0.004241943359375       epoc:  9\nloss:  0.0007390975952148438       epoc:  9\nloss:  0.0001571178436279297       epoc:  9\nloss:  0.0015714168548583984       epoc:  9\nloss:  0.04034841060638428       epoc:  9\nloss:  0.00013256072998046875       epoc:  9\nloss:  0.10708093643188477       epoc:  9\nloss:  0.1080636978149414       epoc:  9\nloss:  0.028762102127075195       epoc:  9\nloss:  0.06070435047149658       epoc:  9\nloss:  0.003905773162841797       epoc:  9\nloss:  0.033744096755981445       epoc:  9\nloss:  0.0026502609252929688       epoc:  9\nloss:  0.04081690311431885       epoc:  9\nloss:  1.6689300537109375e-05       epoc:  9\nloss:  0.10784590244293213       epoc:  9\nloss:  0.20828258991241455       epoc:  9\nloss:  0.06499850749969482       epoc:9\nloss:  0.011959552764892578       epoc:  9\nloss:  0.2814621329307556       epoc:  9\nloss:  7.796287536621094e-05       epoc:  9\nloss:  0.0005087852478027344       epoc:  9\nloss:  0.005070209503173828       epoc:  10\nloss:  0.053838491439819336       epoc:  10\nloss:  3.337860107421875e-05       epoc:  10\nloss:  0.035323262214660645       epoc:  10\nloss:  0.00019621849060058594       epoc:  10\nloss:  0.019406437873840332       epoc:  10\nloss:  0.003968238830566406       epoc:  10\nloss:  0.21972870826721191       epoc:  10\nloss:  0.06279933452606201       epoc:  10\nloss:  0.28606104850769043       epoc:  10\nloss:  0.0003132820129394531       epoc:  10\nloss:  0.0001518726348876953       epoc:  10\nloss:  0.7619762420654297       epoc:  10\nloss:  0.00018310546875       epoc:  10\nloss:  0.0008285045623779297       epoc:  10\nloss:  0.0006649494171142578       epoc:  10\nloss:  0.015238046646118164       epoc:  10\nloss:  0.4209071397781372       epoc:  10\nloss:  1.0967254638671875e-05       epoc:  10\nloss:  0.0007634162902832031       epoc:  10\nloss:  0.011725425720214844       epoc:  10\nloss:  0.0047321319580078125       epoc:  10\nloss:  0.049001336097717285       epoc:  10\nloss:  0.0002300739288330078       epoc:  10\nloss:  0.046474456787109375       epoc:  10\nloss:  0.0487140417098999       epoc:  10\nloss:  0.04373884201049805       epoc:  10\nloss:  0.020685672760009766       epoc:  10\nloss:  0.6803396940231323       epoc:  10\nloss:  0.007622838020324707       epoc:  10\nloss:  0.000644683837890625       epoc:  10\nloss:  0.0005214214324951172       epoc:  10\nloss:  0.009599924087524414       epoc:  10\nloss:  0.012682437896728516       epoc:  10\nloss:  8.511543273925781e-05       epoc:  10\nloss:  0.037101149559020996       epoc:  10\nloss:  0.13630753755569458       epoc:  10\nloss:  0.0022509098052978516       epoc:  10\nloss:  0.004024505615234375       epoc:  10\nloss:  0.008278369903564453       epoc:  10\nloss:  0.18785232305526733       epoc:  10\nloss:  0.07872027158737183       epoc:  10\nloss:  0.6077259182929993       epoc:  10\nloss:  0.027524828910827637       epoc:  10\nloss:  0.00023031234741210938       epoc:  10\nloss:  0.0002856254577636719       epoc:  10\nloss:  0.000667572021484375       epoc:  10\nloss:  9.703636169433594e-05       epoc:  10\nloss:  0.018145084381103516       epoc:  10\nloss:  0.0004489421844482422       epoc:  10\nloss:  0.0027773380279541016       epoc:  10\nloss:  0.004309415817260742       epoc:  10\nloss:  0.00010251998901367188       epoc:  10\nloss:  5.7220458984375e-06       epoc:  10\nloss:  0.0002608299255371094       epoc:  10\nloss:  0.02429807186126709       epoc:  10\nloss:  9.5367431640625e-07       epoc:  10\nloss:  0.0012340545654296875       epoc:  10\nloss:  0.0024805068969726562       epoc:  10\nloss:  0.005372285842895508       epoc:  10\nloss:  0.03396153450012207       epoc:  10\nloss:  0.07532620429992676       epoc:  10\nloss:  1.9073486328125e-06       epoc:  10\nloss:  1.3013184070587158       epoc:  10\nloss:  0.6707183122634888       epoc:  10\nloss:  0.040757060050964355       epoc:  10\nloss:  0.023405075073242188       epoc:  10\nloss:  0.0004582405090332031       epoc:  10\nloss:  0.0015914440155029297       epoc:  10\nloss:  0.0       epoc:  10\nloss:  0.0016182661056518555       epoc:  10\nloss:  0.02152872085571289       epoc:  10\nloss:  5.7220458984375e-06       epoc:  10\nloss:  0.005662679672241211       epoc:  10\nloss:  1.2636184692382812e-05       epoc:  10\nloss:  9.298324584960938e-05       epoc:  10\nloss:  0.03411424160003662       epoc:  10\nloss:  0.003081798553466797       epoc:  10\nloss:  0.054151058197021484       epoc:  10\nloss:  7.367134094238281e-05       epoc:  10\nloss:  0.04187428951263428       epoc:  10\nloss:  0.004891395568847656       epoc:  10\nloss:  0.004247307777404785       epoc:  10\nloss:  0.030349552631378174       epoc:  10\nloss:  0.0019884109497070312       epoc:  10\nloss:  1.0302619934082031       epoc:  10\nloss:  0.015170097351074219       epoc:  10\nloss:  0.001520395278930664       epoc:  10\nloss:  0.00791788101196289       epoc:  10\nloss:  4.8160552978515625e-05       epoc:  10\nloss:  0.00955498218536377       epoc:  10\nloss:  0.0029342174530029297       epoc:  10\nloss:  0.0006985664367675781       epoc:  10\nloss:  0.0039255619049072266       epoc:  10\nloss:  0.001978158950805664       epoc:  10\nloss:  0.04872548580169678       epoc:  10\nloss:  0.0120849609375       epoc:  10\nloss:  0.45102596282958984       epoc:  10\nloss:  0.019489288330078125       epoc:  10\nloss:  0.04685318470001221       epoc:  10\nloss:  0.23044198751449585       epoc:  10\nloss:  0.0008242130279541016       epoc:  10\nloss:  0.012999773025512695       epoc:  10\nloss:  0.0010235309600830078       epoc:  10\nloss:  0.001448988914489746       epoc:  10\nloss:  0.0       epoc:  10\nloss:  0.0037059783935546875       epoc:  10\nloss:  8.678436279296875e-05       epoc:  10\nloss:  0.013663768768310547       epoc:  10\nloss:  4.76837158203125e-07       epoc:  10\nloss:  8.320808410644531e-05       epoc:  10\nloss:  5.316734313964844e-05       epoc:  10\nloss:  0.0013163089752197266       epoc:  10\nloss:  0.0001800060272216797       epoc:  10\nloss:  0.00022268295288085938       epoc:  10\nloss:  0.42150068283081055       epoc:  10\nloss:  0.04898726940155029       epoc:  10\nloss:  4.9591064453125e-05       epoc:  10\nloss:  7.05718994140625e-05       epoc:  10\nloss:  0.26534974575042725       epoc:  10\nloss:  1.7642974853515625e-05       epoc:  10\nloss:  0.00020503997802734375       epoc:  10\nloss:  5.650520324707031e-05       epoc:  10\nloss:  0.0004799365997314453       epoc:  10\nloss:  0.000263214111328125       epoc:  10\nloss:  0.0015230178833007812       epoc:  10\nloss:  0.031762123107910156       epoc:  10\nloss:  1.8835067749023438e-05       epoc:  10\nloss:  0.07900440692901611       epoc:  10\nloss:  0.00035691261291503906       epoc:  10\nloss:  0.0       epoc:  10\nloss:  0.004203081130981445       epoc:  10\nloss:  0.00014090538024902344       epoc:  10\nloss:  1.52587890625e-05       epoc:  10\nloss:  1.621246337890625e-05       epoc:  10\nloss:  0.012296915054321289       epoc:  10\nloss:  0.00272369384765625       epoc:  10\nloss:  0.016080617904663086       epoc:  10\nloss:  3.24249267578125e-05       epoc:  10\nloss:  0.06257307529449463       epoc:  10\nloss:  3.814697265625e-06       epoc:  10\nloss:  0.1105501651763916       epoc:  10\nloss:  0.0012698173522949219       epoc:  10\nloss:  0.00010347366333007812       epoc:  10\nloss:  0.1966465413570404       epoc:  10\nloss:  8.988380432128906e-05       epoc:  10\nloss:  2.86102294921875e-05       epoc:  10\nloss:  1.2874603271484375e-05       epoc:  10\nloss:  0.0799410343170166       epoc:  10\nloss:  0.0016543865203857422       epoc:  10\nloss:  0.05195307731628418       epoc:  10\nloss:  0.0003008842468261719       epoc:  10\nloss:  0.0018868446350097656       epoc:  10\nloss:  0.0011646747589111328       epoc:  10\nloss:  0.0006642341613769531       epoc:  10\nloss:  0.005465269088745117       epoc:  10\nloss:  0.002790689468383789       epoc:  10\nloss:  0.0010304450988769531       epoc:  10\nloss:  0.0038216114044189453       epoc:  10\nloss:  4.6253204345703125e-05       epoc:  10\nloss:  0.05324971675872803       epoc:  10\nloss:  0.46425700187683105       epoc:  10\nloss:  0.002031564712524414       epoc:  10\nloss:  0.001402139663696289       epoc:  10\nloss:  0.0       epoc:  10\nloss:  2.1457672119140625e-06       epoc:  10\nloss:  4.76837158203125e-07       epoc:  10\nloss:  4.0531158447265625e-05       epoc:  10\nloss:  0.0017566680908203125       epoc:  10\nloss:  0.0008745193481445312       epoc:  10\nloss:  1.4781951904296875e-05       epoc:  10\nloss:  7.152557373046875e-05       epoc:  10\nloss:  0.0002815723419189453       epoc:  10\nloss:  1.239776611328125e-05       epoc:  10\nloss:  0.0035033226013183594       epoc:  10\nloss:  1.5020370483398438e-05       epoc:  10\nloss:  4.291534423828125e-06       epoc:  10\nloss:  0.0       epoc:  10\nloss:  0.0       epoc:  10\nloss:  9.751319885253906e-05       epoc:  10\nloss:  0.002976655960083008       epoc:  10\nloss:  4.0531158447265625e-06       epoc:  10\nloss:  0.0002124309539794922       epoc:  10\nloss:  0.01495051383972168       epoc:  10\nloss:  4.76837158203125e-06       epoc:  10\nloss:  0.0033344030380249023       epoc:  10\nloss:  0.002859830856323242       epoc:  10\nloss:  0.01905834674835205       epoc:  10\nloss:  6.198883056640625e-06       epoc:  10\nloss:  3.337860107421875e-06       epoc:  10\nloss:  0.001972198486328125       epoc:  10\nloss:  0.05743575096130371       epoc:  10\nloss:  0.0005666017532348633       epoc:  10\nloss:  0.0014450550079345703       epoc:  10\nloss:  9.5367431640625e-07       epoc:  10\nloss:  1.9073486328125e-06       epoc:  10\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e0112d590d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#calculate the gradients automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#upgrade parametters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'      epoc: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epocs):\n",
    "    \n",
    "\n",
    "    for inputs, targets in dataLoader['train']:\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()#after each epoc i going to research for a new best result so i put the gradient on 0 cause i'll start all over again\n",
    "\n",
    "        outputs = net(inputs)#fitting my images in the network to obtain a result to be used to predict \n",
    "        \n",
    "\n",
    "        loss = loss_fn(outputs, targets) #get the loss\n",
    "\n",
    "        loss.backward() #calculate the gradients automatically\n",
    " \n",
    "        optimizer.step() #upgrade parametters\n",
    "\n",
    "        print('loss: ',loss.item(),'      epoc: ',epoch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valSet = Loader('val_signs',transform)\n",
    "image , label = valSet2[20]\n",
    "image = image.unsqueeze(0)\n",
    "image = torch.tensor(image,dtype=torch.float32)\n",
    "image = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.eval()\n",
    "out = net(image)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}